https://www.kaggle.com/models/google/movenet/frameworks/tfLite

Movenet multipose lightning float 16

Input
A frame of video or an image, represented as an int32 tensor of dynamic shape:
    H and W need to be a multiple of 32
    larger dim is recommended to be 256
To prepare the input image tensor, one should resize and/or pad such that above conditions hold

Output
A float32 tensor of shape [1, 6, 56].
    The first dim is batch dim, which is always equal to 1.
    The second dim corresponds to the maximum number of instance detections. The model can detect up to 6 people in the image frame simultaneously.
    The third dim represents the predicted bounding box/keypoint locations and scores. The first 17 * 3 elements are the keypoint locations and scores in the format: [y_0, x_0, s_0, y_1, x_1, s_1, â€¦, y_16, x_16, s_16], where y_i, x_i, s_i are the yx-coordinates (normalized to image frame, e.g. range in [0.0, 1.0]) and confidence scores of the i-th joint correspondingly. The order of the 17 keypoint joints is: [nose, left eye, right eye, left ear, right ear, left shoulder, right shoulder, left elbow, right elbow, left wrist, right wrist, left hip, right hip, left knee, right knee, left ankle, right ankle]. The remaining 5 elements [ymin, xmin, ymax, xmax, score] represent the region of the bounding box (in normalized coordinates) and the confidence score of the instance.
